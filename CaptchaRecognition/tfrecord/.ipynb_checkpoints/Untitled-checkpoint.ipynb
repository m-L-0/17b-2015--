{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np  \n",
    "import glob  \n",
    "import random  \n",
    "from PIL import Image   \n",
    "import configparser  \n",
    "import os  \n",
    "\n",
    "IMAGE_HEIGHT = 36  \n",
    "IMAGE_WIDTH = 48  \n",
    "MAX_CAPTCHA = 4 \n",
    "CHAR_SET_LEN = 11 \n",
    "\n",
    "\n",
    "####################################################################  \n",
    "#读热编码\n",
    "def Onehot(text):\n",
    "    vector = list()\n",
    "    lentext = len(text)\n",
    "    for i in range(lentext):\n",
    "         vector.append(np.zeros(4 * 11))\n",
    "    for i,s in enumerate(text):\n",
    "        s = str(s)\n",
    "        for index,n in enumerate (s):\n",
    "            vector[i][(index)*11+int(n)] = 1\n",
    "        if index < 4:\n",
    "            for m in range(index+1,4):\n",
    "                vector[i][(m)*11+10] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "# 定义CNN  \n",
    "def crack_captcha_cnn(X, keep_prob, w_alpha=0.01, b_alpha=0.1):  \n",
    "    x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])  \n",
    "    # print(x.get_shape())  \n",
    "\n",
    "    # w_c1_alpha = np.sqrt(2.0/(IMAGE_HEIGHT*IMAGE_WIDTH)) #  \n",
    "    # w_c2_alpha = np.sqrt(2.0/(3*3*32))  \n",
    "    # w_c3_alpha = np.sqrt(2.0/(3*3*64))  \n",
    "    # w_d1_alpha = np.sqrt(2.0/(8*32*64))  \n",
    "    # out_alpha = np.sqrt(2.0/1024)  \n",
    "\n",
    "    # 3 conv layer  \n",
    "    w_c1 = tf.Variable(w_alpha * tf.random_normal([3, 3, 1, 32]))  \n",
    "    b_c1 = tf.Variable(b_alpha * tf.random_normal([32]))  \n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='VALID'), b_c1))  \n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  \n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)  \n",
    "    # print(conv1.get_shape())  \n",
    "\n",
    "    w_c2 = tf.Variable(w_alpha * tf.random_normal([3, 3, 32, 64]))  \n",
    "    b_c2 = tf.Variable(b_alpha * tf.random_normal([64]))  \n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='VALID'), b_c2))  \n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  \n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)  \n",
    "    # print(conv2.get_shape())  \n",
    "\n",
    "    w_c3 = tf.Variable(w_alpha * tf.random_normal([3, 3, 64, 64]))  \n",
    "    b_c3 = tf.Variable(b_alpha * tf.random_normal([64]))  \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='VALID'), b_c3))  \n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  \n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob) \n",
    "    # print(conv3.get_shape())  \n",
    "\n",
    "    # Fully connected layer  \n",
    "    w_d = tf.Variable(w_alpha * tf.random_normal([3*5*64, 1024]))  \n",
    "    b_d = tf.Variable(b_alpha * tf.random_normal([1024]))  \n",
    "    dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])  \n",
    "    dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))  \n",
    "    dense = tf.nn.dropout(dense, keep_prob)  \n",
    "\n",
    "    w_out = tf.Variable(w_alpha * tf.random_normal([1024, MAX_CAPTCHA * CHAR_SET_LEN]))  \n",
    "    b_out = tf.Variable(b_alpha * tf.random_normal([MAX_CAPTCHA * CHAR_SET_LEN]))  \n",
    "    out = tf.add(tf.matmul(dense, w_out), b_out)  \n",
    "    # out = tf.nn.softmax(out)  \n",
    "    return out  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = \"../img/\"\n",
    "dirs = os.listdir(cwd)\n",
    "img = Image.open(cwd+dirs[0])\n",
    "img = img.resize((24, 48))\n",
    "x_t = np.array(img)#将图片转化为原生bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "restore() missing 1 required positional argument: 'save_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-85ec29afdedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#saver.restore(sess, tf.train.latest_checkpoint('./model/'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: restore() missing 1 required positional argument: 'save_path'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('./model/'))\n",
    "    model_file=tf.train.latest_checkpoint('model/')\n",
    "    tf.train.Save.restore(sess,model_file)\n",
    "        \n",
    "    acc = sess.run(accuracy, feed_dict={X: x_t})\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
