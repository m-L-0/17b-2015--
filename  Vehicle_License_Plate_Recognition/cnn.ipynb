{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#导入数据\n",
    "def read_and_decode(filename):\n",
    "    #根据文件名生成一个队列\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       })\n",
    "\n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    img = tf.cast(img,tf.float64)\n",
    "\n",
    "    img = tf.reshape(img, [48, 24, 3])\n",
    "    img=tf.split(img,3,2)[0]\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img, label],\n",
    "                                                batch_size=64, capacity=25000,\n",
    "                                                min_after_dequeue=10000)\n",
    "    \n",
    "    return img_batch, label_batch\n",
    "\n",
    "def read_and_decode1(filename):\n",
    "    #根据文件名生成一个队列\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       })\n",
    "\n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    img = tf.cast(img,tf.float64)\n",
    "\n",
    "    img = tf.reshape(img, [48, 24, 3])\n",
    "    img=tf.split(img,3,2)[0]\n",
    "    label = tf.cast(features['label'], tf.int32) \n",
    "    return img_batch, label_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dr(a):\n",
    "    s = list()\n",
    "    for index, i in enumerate(a):\n",
    "        s.append(list())\n",
    "        for n in range(34):\n",
    "            if n == i:\n",
    "                s[index].append(1)\n",
    "            else:\n",
    "                s[index].append(0)            \n",
    "    return s\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "权重初始化,\n",
    "初始化为一个接近0的很小的正数\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "       \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "#卷积:步长为1,0边距\n",
    "def juanji(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "\n",
    "def chihua(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "#MNIST数据输入\n",
    "\n",
    "\n",
    "#第一层 卷积层\n",
    "x = tf.placeholder(tf.float32,[None, 48,24,1])\n",
    "\n",
    "#最后一维代表通道，如果是rgb则为3 \n",
    "x_image = tf.reshape(x, [-1, 48, 24, 1])\n",
    "# 第一二参数值得卷积核尺寸大小，即patch，第三个参数是图像通道数，第四个参数是卷积核的数目，代表会出现多少个卷积特征图像;  \n",
    "W_1 = weight_variable([5, 5, 1, 32])\n",
    "# 对于每一个卷积核都有一个对应的偏置量。\n",
    "b_1 = bias_variable([32])\n",
    "# 图片乘以卷积核，并加上偏执量，\n",
    "h_j1 = tf.nn.relu(juanji(x_image, W_1) + b_1)\n",
    "h_c1 = chihua(h_j1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#第二层 卷积层\n",
    "# 32通道卷积，卷积出64个特征 \n",
    "W_2 = weight_variable([5, 5, 32, 64])\n",
    "# 64个偏执数据 \n",
    "b_2 = bias_variable([64])\n",
    "h_j2 = tf.nn.relu(juanji(h_c1, W_2) + b_2)\n",
    "h_c2 = chihua(h_j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#第三层 全连接层\n",
    "W_f1 = weight_variable([9 * 3 * 64, 1024])\n",
    "b_f1 = bias_variable([1024])\n",
    "h_c2_flat = tf.reshape(h_c2, [-1, 9 * 3 * 64])\n",
    "h_f1 = tf.nn.relu(tf.matmul(h_c2_flat, W_f1) + b_f1)\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_f1_drop = tf.nn.dropout(h_f1, keep_prob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#第四层 Softmax输出层\n",
    "\n",
    "W_f2 = weight_variable([1024, 34])\n",
    "b_f2 = bias_variable([34])\n",
    "logits = tf.matmul(h_f1_drop, W_f2) + b_f2\n",
    "#Y = tf.nn.softmax(tf.matmul(h_f1_drop, W_f2) + b_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float32\", [None, 34])\n",
    "#cross_entropy = -tf.reduce_sum(y_ * tf.log(Y + 1e-10)) # 定义交叉熵为loss函数    \n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy) # 调用优化\n",
    "saver = tf.train.Saver()\n",
    "Y = tf.nn.softmax(logits)\n",
    "correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(y_,1))  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "img_batch ,label_batch = read_and_decode(\"train.tfrecords\")\n",
    "img_v_batch ,label_v_batch = read_and_decode1(\"validation.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "#保存最优的三个\n",
    "#幷记录每100次的正确率\n",
    "saver=tf.train.Saver(max_to_keep=3)\n",
    "max_train_accuracy=0\n",
    "f=open('model/acc.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.03125\n",
      "step 100, training accuracy 0.140625\n",
      "step 200, training accuracy 0.078125\n",
      "step 300, training accuracy 0.0625\n",
      "step 400, training accuracy 0.078125\n",
      "step 500, training accuracy 0.0625\n",
      "step 600, training accuracy 0.046875\n",
      "step 700, training accuracy 0.046875\n",
      "step 800, training accuracy 0.15625\n",
      "step 900, training accuracy 0.03125\n",
      "step 1000, training accuracy 0.09375\n",
      "step 1100, training accuracy 0.0625\n",
      "step 1200, training accuracy 0.0625\n",
      "step 1300, training accuracy 0.109375\n",
      "step 1400, training accuracy 0.078125\n",
      "step 1500, training accuracy 0.0625\n",
      "step 1600, training accuracy 0.078125\n",
      "step 1700, training accuracy 0.078125\n",
      "step 1800, training accuracy 0.109375\n",
      "step 1900, training accuracy 0.078125\n",
      "step 2000, training accuracy 0.109375\n",
      "step 2100, training accuracy 0.125\n",
      "step 2200, training accuracy 0.125\n",
      "step 2300, training accuracy 0.1875\n",
      "step 2400, training accuracy 0.140625\n",
      "step 2500, training accuracy 0.40625\n",
      "step 2600, training accuracy 0.40625\n",
      "step 2700, training accuracy 0.421875\n",
      "step 2800, training accuracy 0.46875\n",
      "step 2900, training accuracy 0.5\n",
      "step 3000, training accuracy 0.53125\n",
      "step 3100, training accuracy 0.609375\n",
      "step 3200, training accuracy 0.640625\n",
      "step 3300, training accuracy 0.734375\n",
      "step 3400, training accuracy 0.703125\n",
      "step 3500, training accuracy 0.8125\n",
      "step 3600, training accuracy 0.859375\n",
      "step 3700, training accuracy 0.890625\n",
      "step 3800, training accuracy 0.96875\n",
      "step 3900, training accuracy 0.921875\n",
      "step 4000, training accuracy 0.921875\n",
      "step 4100, training accuracy 0.890625\n",
      "step 4200, training accuracy 0.90625\n",
      "step 4300, training accuracy 0.96875\n",
      "step 4400, training accuracy 0.96875\n",
      "step 4500, training accuracy 0.96875\n",
      "step 4600, training accuracy 0.96875\n",
      "step 4700, training accuracy 0.9375\n",
      "step 4800, training accuracy 0.953125\n",
      "step 4900, training accuracy 0.953125\n",
      "validation accuracy 0.9375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./logs', graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    #训练阶段\n",
    "    for i in range(5000):\n",
    "        img, label = sess.run([img_batch, label_batch]) \n",
    "        #print(label[0])\n",
    "        label = dr(label)\n",
    "        #plt.imshow(img[0].reshape(48,24),cmap=\"gray\")\n",
    "        #plt.show()\n",
    "        \n",
    "        if i%100 == 0:  \n",
    "            train_accuracy = accuracy.eval(feed_dict={x:img, y_: label, keep_prob: 1.0})  \n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy)) \n",
    "            f.write(str(i+1)+', train_accuracy: '+str(train_accuracy)+'\\n')\n",
    "            if train_accuracy>max_train_accuracy:\n",
    "                max_train_accuracy = train_accuracy\n",
    "                saver.save(sess,'model/mnist.ckpt',global_step=i+1)\n",
    "        train_step.run(feed_dict={x:img, y_: label, keep_prob: 0.5}) \n",
    "    f.close()\n",
    "    \n",
    "    #模型的恢复\n",
    "    model_file=tf.train.latest_checkpoint('model/')\n",
    "    saver.restore(sess,model_file)\n",
    "    #验证阶段\n",
    "    img_v, label_v = sess.run([img_v_batch, label_v_batch])\n",
    "    label_v = dr(label_v)\n",
    "    print(\"validation accuracy %g\" %accuracy.eval(session = sess,feed_dict = {x:img_v, y_:label_v,keep_prob:1.0}))\n",
    "    \n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
